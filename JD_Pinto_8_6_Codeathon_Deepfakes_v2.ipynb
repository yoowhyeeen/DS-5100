{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNa1x8cj4QteDXlazhRVUkZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoowhyeeen/DS-5100/blob/master/JD_Pinto_8_6_Codeathon_Deepfakes_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JD Pinto (jp5ph)"
      ],
      "metadata": {
        "id": "hZRh5yt75cGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DariusAf/MesoNet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP-jqgVI3aYQ",
        "outputId": "5a8e1e8b-98ec-44c3-c892-e85b298ac13b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MesoNet'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 78 (delta 1), reused 3 (delta 1), pack-reused 70\u001b[K\n",
            "Unpacking objects: 100% (78/78), 495.77 KiB | 6.61 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io9vPGZjXHB0",
        "outputId": "b147a6f7-e4a9-4f58-9f41-1907ca8810dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-99ca8974e406>:9: DeprecationWarning: Please use `zoom` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  from scipy.ndimage.interpolation import zoom, rotate\n",
            "<ipython-input-18-99ca8974e406>:9: DeprecationWarning: Please use `rotate` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  from scipy.ndimage.interpolation import zoom, rotate\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (2.25.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.9/dist-packages (from imageio) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from imageio) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from face_recognition) (1.22.4)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (19.24.1)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from face_recognition) (8.4.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=c39c48ea391532f79e3e3c310b7c623cd627123a396680d25a70308ec7679814\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/a8/60/4a2aeb763d63f50190f4c4e07069a22245347eeafdb3a67551\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n"
          ]
        }
      ],
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "\n",
        "import random\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import numpy as np\n",
        "from math import floor\n",
        "from scipy.ndimage.interpolation import zoom, rotate\n",
        "\n",
        "!pip install imageio\n",
        "import imageio\n",
        "!pip install face_recognition\n",
        "import face_recognition\n",
        "\n",
        "\n",
        "## Face extraction\n",
        "\n",
        "class Video:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.container = imageio.get_reader(path, 'ffmpeg')\n",
        "        self.length = self.container.count_frames()\n",
        "        self.fps = self.container.get_meta_data()['fps']\n",
        "    \n",
        "    def init_head(self):\n",
        "        self.container.set_image_index(0)\n",
        "    \n",
        "    def next_frame(self):\n",
        "        self.container.get_next_data()\n",
        "    \n",
        "    def get(self, key):\n",
        "        return self.container.get_data(key)\n",
        "    \n",
        "    def __call__(self, key):\n",
        "        return self.get(key)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class FaceFinder(Video):\n",
        "    def __init__(self, path, load_first_face = True):\n",
        "        super().__init__(path)\n",
        "        self.faces = {}\n",
        "        self.coordinates = {}  # stores the face (locations center, rotation, length)\n",
        "        self.last_frame = self.get(0)\n",
        "        self.frame_shape = self.last_frame.shape[:2]\n",
        "        self.last_location = (0, 200, 200, 0)\n",
        "        if (load_first_face):\n",
        "            face_positions = face_recognition.face_locations(self.last_frame, number_of_times_to_upsample=2)\n",
        "            if len(face_positions) > 0:\n",
        "                self.last_location = face_positions[0]\n",
        "    \n",
        "    def load_coordinates(self, filename):\n",
        "        np_coords = np.load(filename)\n",
        "        self.coordinates = np_coords.item()\n",
        "    \n",
        "    def expand_location_zone(self, loc, margin = 0.2):\n",
        "        ''' Adds a margin around a frame slice '''\n",
        "        offset = round(margin * (loc[2] - loc[0]))\n",
        "        y0 = max(loc[0] - offset, 0)\n",
        "        x1 = min(loc[1] + offset, self.frame_shape[1])\n",
        "        y1 = min(loc[2] + offset, self.frame_shape[0])\n",
        "        x0 = max(loc[3] - offset, 0)\n",
        "        return (y0, x1, y1, x0)\n",
        "    \n",
        "    @staticmethod\n",
        "    def upsample_location(reduced_location, upsampled_origin, factor):\n",
        "        ''' Adapt a location to an upsampled image slice '''\n",
        "        y0, x1, y1, x0 = reduced_location\n",
        "        Y0 = round(upsampled_origin[0] + y0 * factor)\n",
        "        X1 = round(upsampled_origin[1] + x1 * factor)\n",
        "        Y1 = round(upsampled_origin[0] + y1 * factor)\n",
        "        X0 = round(upsampled_origin[1] + x0 * factor)\n",
        "        return (Y0, X1, Y1, X0)\n",
        "\n",
        "    @staticmethod\n",
        "    def pop_largest_location(location_list):\n",
        "        max_location = location_list[0]\n",
        "        max_size = 0\n",
        "        if len(location_list) > 1:\n",
        "            for location in location_list:\n",
        "                size = location[2] - location[0]\n",
        "                if size > max_size:\n",
        "                    max_size = size\n",
        "                    max_location = location\n",
        "        return max_location\n",
        "    \n",
        "    @staticmethod\n",
        "    def L2(A, B):\n",
        "        return np.sqrt(np.sum(np.square(A - B)))\n",
        "    \n",
        "    def find_coordinates(self, landmark, K = 2.2):\n",
        "        '''\n",
        "        We either choose K * distance(eyes, mouth),\n",
        "        or, if the head is tilted, K * distance(eye 1, eye 2)\n",
        "        /!\\ landmarks coordinates are in (x,y) not (y,x)\n",
        "        '''\n",
        "        E1 = np.mean(landmark['left_eye'], axis=0)\n",
        "        E2 = np.mean(landmark['right_eye'], axis=0)\n",
        "        E = (E1 + E2) / 2\n",
        "        N = np.mean(landmark['nose_tip'], axis=0) / 2 + np.mean(landmark['nose_bridge'], axis=0) / 2\n",
        "        B1 = np.mean(landmark['top_lip'], axis=0)\n",
        "        B2 = np.mean(landmark['bottom_lip'], axis=0)\n",
        "        B = (B1 + B2) / 2\n",
        "\n",
        "        C = N\n",
        "        l1 = self.L2(E1, E2)\n",
        "        l2 = self.L2(B, E)\n",
        "        l = max(l1, l2) * K\n",
        "        if (B[1] == E[1]):\n",
        "            if (B[0] > E[0]):\n",
        "                rot = 90\n",
        "            else:\n",
        "                rot = -90\n",
        "        else:\n",
        "            rot = np.arctan((B[0] - E[0]) / (B[1] - E[1])) / np.pi * 180\n",
        "        \n",
        "        return ((floor(C[1]), floor(C[0])), floor(l), rot)\n",
        "    \n",
        "    \n",
        "    def find_faces(self, resize = 0.5, stop = 0, skipstep = 0, no_face_acceleration_threshold = 3, cut_left = 0, cut_right = -1, use_frameset = False, frameset = []):\n",
        "        '''\n",
        "        The core function to extract faces from frames\n",
        "        using previous frame location and downsampling to accelerate the loop.\n",
        "        '''\n",
        "        not_found = 0\n",
        "        no_face = 0\n",
        "        no_face_acc = 0\n",
        "        \n",
        "        # to only deal with a subset of a video, for instance I-frames only\n",
        "        if (use_frameset):\n",
        "            finder_frameset = frameset\n",
        "        else:\n",
        "            if (stop != 0):\n",
        "                finder_frameset = range(0, min(self.length, stop), skipstep + 1)\n",
        "            else:\n",
        "                finder_frameset = range(0, self.length, skipstep + 1)\n",
        "        \n",
        "        # Quick face finder loop\n",
        "        for i in finder_frameset:\n",
        "            # Get frame\n",
        "            frame = self.get(i)\n",
        "            if (cut_left != 0 or cut_right != -1):\n",
        "                frame[:, :cut_left] = 0\n",
        "                frame[:, cut_right:] = 0            \n",
        "            \n",
        "            # Find face in the previously found zone\n",
        "            potential_location = self.expand_location_zone(self.last_location)\n",
        "            potential_face_patch = frame[potential_location[0]:potential_location[2], potential_location[3]:potential_location[1]]\n",
        "            potential_face_patch_origin = (potential_location[0], potential_location[3])\n",
        "    \n",
        "            reduced_potential_face_patch = zoom(potential_face_patch, (resize, resize, 1))\n",
        "            reduced_face_locations = face_recognition.face_locations(reduced_potential_face_patch, model = 'cnn')\n",
        "            \n",
        "            if len(reduced_face_locations) > 0:\n",
        "                no_face_acc = 0  # reset the no_face_acceleration mode accumulator\n",
        "\n",
        "                reduced_face_location = self.pop_largest_location(reduced_face_locations)\n",
        "                face_location = self.upsample_location(reduced_face_location,\n",
        "                                                    potential_face_patch_origin,\n",
        "                                                    1 / resize)\n",
        "                self.faces[i] = face_location\n",
        "                self.last_location = face_location\n",
        "                \n",
        "                # extract face rotation, length and center from landmarks\n",
        "                landmarks = face_recognition.face_landmarks(frame, [face_location])\n",
        "                if len(landmarks) > 0:\n",
        "                    # we assume that there is one and only one landmark group\n",
        "                    self.coordinates[i] = self.find_coordinates(landmarks[0])\n",
        "            else:\n",
        "                not_found += 1\n",
        "\n",
        "                if no_face_acc < no_face_acceleration_threshold:\n",
        "                    # Look for face in full frame\n",
        "                    face_locations = face_recognition.face_locations(frame, number_of_times_to_upsample = 2)\n",
        "                else:\n",
        "                    # Avoid spending to much time on a long scene without faces\n",
        "                    reduced_frame = zoom(frame, (resize, resize, 1))\n",
        "                    face_locations = face_recognition.face_locations(reduced_frame)\n",
        "                    \n",
        "                if len(face_locations) > 0:\n",
        "                    print('Face extraction warning : ', i, '- found face in full frame', face_locations)\n",
        "                    no_face_acc = 0  # reset the no_face_acceleration mode accumulator\n",
        "                    \n",
        "                    face_location = self.pop_largest_location(face_locations)\n",
        "                    \n",
        "                    # if was found on a reduced frame, upsample location\n",
        "                    if no_face_acc > no_face_acceleration_threshold:\n",
        "                        face_location = self.upsample_location(face_location, (0, 0), 1 / resize)\n",
        "                    \n",
        "                    self.faces[i] = face_location\n",
        "                    self.last_location = face_location\n",
        "                    \n",
        "                    # extract face rotation, length and center from landmarks\n",
        "                    landmarks = face_recognition.face_landmarks(frame, [face_location])\n",
        "                    if len(landmarks) > 0:\n",
        "                        self.coordinates[i] = self.find_coordinates(landmarks[0])\n",
        "                else:\n",
        "                    print('Face extraction warning : ',i, '- no face')\n",
        "                    no_face_acc += 1\n",
        "                    no_face += 1\n",
        "\n",
        "        print('Face extraction report of', 'not_found :', not_found)\n",
        "        print('Face extraction report of', 'no_face :', no_face)\n",
        "        return 0\n",
        "    \n",
        "    def get_face(self, i):\n",
        "        ''' Basic unused face extraction without alignment '''\n",
        "        frame = self.get(i)\n",
        "        if i in self.faces:\n",
        "            loc = self.faces[i]\n",
        "            patch = frame[loc[0]:loc[2], loc[3]:loc[1]]\n",
        "            return patch\n",
        "        return frame\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_image_slice(img, y0, y1, x0, x1):\n",
        "        '''Get values outside the domain of an image'''\n",
        "        m, n = img.shape[:2]\n",
        "        padding = max(-y0, y1-m, -x0, x1-n, 0)\n",
        "        padded_img = np.pad(img, ((padding, padding), (padding, padding), (0, 0)), 'reflect')\n",
        "        return padded_img[(padding + y0):(padding + y1),\n",
        "                        (padding + x0):(padding + x1)]\n",
        "    \n",
        "    def get_aligned_face(self, i, l_factor = 1.3):\n",
        "        '''\n",
        "        The second core function that converts the data from self.coordinates into an face image.\n",
        "        '''\n",
        "        frame = self.get(i)\n",
        "        if i in self.coordinates:\n",
        "            c, l, r = self.coordinates[i]\n",
        "            l = int(l) * l_factor # fine-tuning the face zoom we really want\n",
        "            dl_ = floor(np.sqrt(2) * l / 2) # largest zone even when rotated\n",
        "            patch = self.get_image_slice(frame,\n",
        "                                    floor(c[0] - dl_),\n",
        "                                    floor(c[0] + dl_),\n",
        "                                    floor(c[1] - dl_),\n",
        "                                    floor(c[1] + dl_))\n",
        "            rotated_patch = rotate(patch, -r, reshape=False)\n",
        "            # note : dl_ is the center of the patch of length 2dl_\n",
        "            return self.get_image_slice(rotated_patch,\n",
        "                                    floor(dl_-l//2),\n",
        "                                    floor(dl_+l//2),\n",
        "                                    floor(dl_-l//2),\n",
        "                                    floor(dl_+l//2))\n",
        "        return frame\n",
        "\n",
        "\n",
        "## Face prediction\n",
        "\n",
        "class FaceBatchGenerator:\n",
        "    '''\n",
        "    Made to deal with framesubsets of video.\n",
        "    '''\n",
        "    def __init__(self, face_finder, target_size = 256):\n",
        "        self.finder = face_finder\n",
        "        self.target_size = target_size\n",
        "        self.head = 0\n",
        "        self.length = int(face_finder.length)\n",
        "\n",
        "    def resize_patch(self, patch):\n",
        "        m, n = patch.shape[:2]\n",
        "        return zoom(patch, (self.target_size / m, self.target_size / n, 1))\n",
        "    \n",
        "    def next_batch(self, batch_size = 50):\n",
        "        batch = np.zeros((1, self.target_size, self.target_size, 3))\n",
        "        stop = min(self.head + batch_size, self.length)\n",
        "        i = 0\n",
        "        while (i < batch_size) and (self.head < self.length):\n",
        "            if self.head in self.finder.coordinates:\n",
        "                patch = self.finder.get_aligned_face(self.head)\n",
        "                batch = np.concatenate((batch, np.expand_dims(self.resize_patch(patch), axis = 0)),\n",
        "                                        axis = 0)\n",
        "                i += 1\n",
        "            self.head += 1\n",
        "        return batch[1:]\n",
        "\n",
        "\n",
        "def predict_faces(generator, classifier, batch_size = 50, output_size = 1):\n",
        "    '''\n",
        "    Compute predictions for a face batch generator\n",
        "    '''\n",
        "    n = len(generator.finder.coordinates.items())\n",
        "    profile = np.zeros((1, output_size))\n",
        "    for epoch in range(n // batch_size + 1):\n",
        "        face_batch = generator.next_batch(batch_size = batch_size)\n",
        "        prediction = classifier.predict(face_batch)\n",
        "        if (len(prediction) > 0):\n",
        "            profile = np.concatenate((profile, prediction))\n",
        "    return profile[1:]\n",
        "\n",
        "\n",
        "def compute_accuracy(classifier, dirname, frame_subsample_count = 30):\n",
        "    '''\n",
        "    Extraction + Prediction over a video\n",
        "    '''\n",
        "    filenames = [f for f in listdir(dirname) if isfile(join(dirname, f)) and ((f[-4:] == '.mp4') or (f[-4:] == '.avi') or (f[-4:] == '.mov'))]\n",
        "    predictions = {}\n",
        "    \n",
        "    for vid in filenames:\n",
        "        print('Dealing with video ', vid)\n",
        "        \n",
        "        # Compute face locations and store them in the face finder\n",
        "        face_finder = FaceFinder(join(dirname, vid), load_first_face = False)\n",
        "        skipstep = max(floor(face_finder.length / frame_subsample_count), 0)\n",
        "        face_finder.find_faces(resize=0.5, skipstep = skipstep)\n",
        "        \n",
        "        print('Predicting ', vid)\n",
        "        gen = FaceBatchGenerator(face_finder)\n",
        "        p = predict_faces(gen, classifier)\n",
        "        \n",
        "        predictions[vid[:-4]] = (np.mean(p > 0.5), p)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model as KerasModel\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "IMGWIDTH = 256\n",
        "\n",
        "class Classifier:\n",
        "    def __init__():\n",
        "        self.model = 0\n",
        "    \n",
        "    def predict(self, x):\n",
        "        if x.size == 0:\n",
        "            return []\n",
        "        return self.model.predict(x)\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        return self.model.train_on_batch(x, y)\n",
        "    \n",
        "    def get_accuracy(self, x, y):\n",
        "        return self.model.test_on_batch(x, y)\n",
        "    \n",
        "    def load(self, path):\n",
        "        self.model.load_weights(path)\n",
        "\n",
        "\n",
        "class Meso1(Classifier):\n",
        "    \"\"\"\n",
        "    Feature extraction + Classification\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate = 0.001, dl_rate = 1):\n",
        "        self.model = self.init_model(dl_rate)\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "    \n",
        "    def init_model(self, dl_rate):\n",
        "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
        "        \n",
        "        x1 = Conv2D(16, (3, 3), dilation_rate = dl_rate, strides = 1, padding='same', activation = 'relu')(x)\n",
        "        x1 = Conv2D(4, (1, 1), padding='same', activation = 'relu')(x1)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(8, 8), padding='same')(x1)\n",
        "\n",
        "        y = Flatten()(x1)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "        return KerasModel(inputs = x, outputs = y)\n",
        "\n",
        "\n",
        "class Meso4(Classifier):\n",
        "    def __init__(self, learning_rate = 0.001):\n",
        "        self.model = self.init_model()\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "    \n",
        "    def init_model(self): \n",
        "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
        "        \n",
        "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "        \n",
        "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
        "        \n",
        "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "        \n",
        "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
        "        x4 = BatchNormalization()(x4)\n",
        "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "        \n",
        "        y = Flatten()(x4)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(16)(y)\n",
        "        y = LeakyReLU(alpha=0.1)(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "\n",
        "        return KerasModel(inputs = x, outputs = y)\n",
        "\n",
        "\n",
        "class MesoInception4(Classifier):\n",
        "    def __init__(self, learning_rate = 0.001):\n",
        "        self.model = self.init_model()\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "    \n",
        "    def InceptionLayer(self, a, b, c, d):\n",
        "        def func(x):\n",
        "            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n",
        "            \n",
        "            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n",
        "            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n",
        "            \n",
        "            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n",
        "            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n",
        "            \n",
        "            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n",
        "            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n",
        "\n",
        "            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
        "            \n",
        "            return y\n",
        "        return func\n",
        "    \n",
        "    def init_model(self):\n",
        "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
        "        \n",
        "        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "        \n",
        "        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
        "        \n",
        "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "        \n",
        "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
        "        x4 = BatchNormalization()(x4)\n",
        "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "        \n",
        "        y = Flatten()(x4)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(16)(y)\n",
        "        y = LeakyReLU(alpha=0.1)(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "\n",
        "        return KerasModel(inputs = x, outputs = y)"
      ],
      "metadata": {
        "id": "rRqJKGKPYz9x"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Below"
      ],
      "metadata": {
        "id": "HhwosLhrz5il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#from classifiers import *\n",
        "#from pipeline import *\n",
        "\n",
        "from tensorflow.keras.models import Model as KerasModel\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "IMGWIDTH = 256\n",
        "\n",
        "class Classifier:\n",
        "    def __init__():\n",
        "        self.model = 0\n",
        "    \n",
        "    def predict(self, x):\n",
        "        if x.size == 0:\n",
        "            return []\n",
        "        return self.model.predict(x)\n",
        "    \n",
        "    def fit(self, x, y):\n",
        "        return self.model.train_on_batch(x, y)\n",
        "    \n",
        "    def get_accuracy(self, x, y):\n",
        "        return self.model.test_on_batch(x, y)\n",
        "    \n",
        "    def load(self, path):\n",
        "        self.model.load_weights(path)\n",
        "\n",
        "\n",
        "class Meso1(Classifier):\n",
        "    \"\"\"\n",
        "    Feature extraction + Classification\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate = 0.001, dl_rate = 1):\n",
        "        self.model = self.init_model(dl_rate)\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "    \n",
        "    def init_model(self, dl_rate):\n",
        "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
        "        \n",
        "        x1 = Conv2D(16, (3, 3), dilation_rate = dl_rate, strides = 1, padding='same', activation = 'relu')(x)\n",
        "        x1 = Conv2D(4, (1, 1), padding='same', activation = 'relu')(x1)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(8, 8), padding='same')(x1)\n",
        "\n",
        "        y = Flatten()(x1)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "        return KerasModel(inputs = x, outputs = y)\n",
        "\n",
        "\n",
        "class Meso4(Classifier):\n",
        "    def __init__(self, learning_rate = 0.001):\n",
        "        self.model = self.init_model()\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "    \n",
        "    def init_model(self): \n",
        "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
        "        \n",
        "        x1 = Conv2D(8, (3, 3), padding='same', activation = 'relu')(x)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "        \n",
        "        x2 = Conv2D(8, (5, 5), padding='same', activation = 'relu')(x1)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)\n",
        "        \n",
        "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "        \n",
        "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
        "        x4 = BatchNormalization()(x4)\n",
        "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "        \n",
        "        y = Flatten()(x4)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(16)(y)\n",
        "        y = LeakyReLU(alpha=0.1)(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "\n",
        "        return KerasModel(inputs = x, outputs = y)\n",
        "\n",
        "\n",
        "class MesoInception4(Classifier):\n",
        "    def __init__(self, learning_rate = 0.001):\n",
        "        self.model = self.init_model()\n",
        "        optimizer = Adam(lr = learning_rate)\n",
        "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "    \n",
        "    def InceptionLayer(self, a, b, c, d):\n",
        "        def func(x):\n",
        "            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n",
        "            \n",
        "            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n",
        "            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n",
        "            \n",
        "            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n",
        "            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n",
        "            \n",
        "            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n",
        "            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n",
        "\n",
        "            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
        "            \n",
        "            return y\n",
        "        return func\n",
        "    \n",
        "    def init_model(self):\n",
        "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
        "        \n",
        "        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n",
        "        x1 = BatchNormalization()(x1)\n",
        "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
        "        \n",
        "        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n",
        "        x2 = BatchNormalization()(x2)\n",
        "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
        "        \n",
        "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
        "        x3 = BatchNormalization()(x3)\n",
        "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
        "        \n",
        "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
        "        x4 = BatchNormalization()(x4)\n",
        "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
        "        \n",
        "        y = Flatten()(x4)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(16)(y)\n",
        "        y = LeakyReLU(alpha=0.1)(y)\n",
        "        y = Dropout(0.5)(y)\n",
        "        y = Dense(1, activation = 'sigmoid')(y)\n",
        "\n",
        "        return KerasModel(inputs = x, outputs = y)\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 1 - Load the model and its pretrained weights\n",
        "classifier = Meso4()\n",
        "classifier.load('Meso4_DF.h5')\n",
        "\n",
        "# 2 - Minimial image generator\n",
        "# We did use it to read and compute the prediction by batchs on test videos\n",
        "# but do as you please, the models were trained on 256x256 images in [0,1]^(n*n)\n",
        "\n",
        "dataGenerator = ImageDataGenerator(rescale=1./255)\n",
        "generator = dataGenerator.flow_from_directory(\n",
        "        'MesoNet',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=1,\n",
        "        class_mode='binary',\n",
        "        subset='training')\n",
        "\n",
        "# 3 - Predict\n",
        "X, y = generator.next()\n",
        "print('Predicted :', classifier.predict(X), '\\nReal class :', y)\n",
        "\n",
        "# 4 - Prediction for a video dataset\n",
        "\n",
        "#classifier.load('Meso4_DF.h5')\n",
        "\n",
        "#predictions = compute_accuracy(classifier, 'test_images')\n",
        "#for video_name in predictions:\n",
        "    #print('`{}` video class prediction :'.format(video_name), predictions[video_name][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLgGesAjZAt8",
        "outputId": "c28ffa9d-25c7-4934-f8cc-9144c10da6fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 images belonging to 3 classes.\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "Predicted : [[0.99782073]] \n",
            "Real class : [1.]\n"
          ]
        }
      ]
    }
  ]
}